mod interpreter;
mod lexer;
mod parser;
mod token;

use crate::interpreter::Interpreter;
use crate::lexer::Lexer;
use crate::parser::Parser;

use std::env;
use std::fs::File;
use std::io::{self, Read};

fn main() -> io::Result<()> {
    let args: Vec<String> = env::args().collect();
    if args.len() < 2 {
        eprintln!("Please provide a file path as an argument.");
        std::process::exit(1);
    }

    let file_path = &args[1];
    let mut file = File::open(file_path)?;
    let mut input = String::new();
    file.read_to_string(&mut input)?;

    let input = input.replace("\\t", "\t").replace("\\n", "\n");
    println!("Unescaped input: {:?}", input);

    let lexer = Lexer::new(&input);
    let mut parser = Parser::new(lexer);

    println!("Tokens generated by lexer:");
    while let Some(token) = parser.lexer.next_token() {
        println!("{:?}", token);
    }

    let program = parser.parse();

    let mut interpreter = Interpreter::new();
    interpreter.execute(&program);

    Ok(())
}
